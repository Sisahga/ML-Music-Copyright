{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h1><b>COMP 432 - Machine Learning</b> | <b>Final Project</b> (W2025)</h1>\n",
    "<h3>Machine Learning Model to detect Copyright Infringement in Music</h3>\n",
    "Written by Sisahga Phimmasone - 40210015<br>\n",
    "April 20th, 2025\n"
   ],
   "id": "b41bf3e220dbace6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h3><b>1. Data Preparation and Cleaning</b></h3>\n",
    "\n",
    "The code cells below convert YouTube video links of pairs of songs from the list of historically known copyright infringement cases to MP3.\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_songs_subject_to_plagiarism_disputes\n",
    "\n",
    "See 'copyright_cases.csv' file.\n",
    "Uses yt_dlp library to output YouTube video URLs to .mp3"
   ],
   "id": "850eb7e266f03ef8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h4><b>1.1 Convert YouTube URLs to MP3 with yt_dlp</b></h4>",
   "id": "9aa66d5ad417b613"
  },
  {
   "metadata": {
    "tags": [
     "Convert YouTube to MP3"
    ]
   },
   "cell_type": "code",
   "source": [
    "import yt_dlp\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ],
   "id": "3917e72eaf277278",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Convert YouTube to MP3"
    ]
   },
   "cell_type": "code",
   "source": [
    "mp3_song_dir = \"songs_mp3\"\n",
    "os.makedirs(mp3_song_dir, exist_ok=True)\n",
    "df = pd.read_csv(\"copyright_cases.csv\")"
   ],
   "id": "c1ca5f777de7ce66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Convert YouTube to MP3"
    ]
   },
   "cell_type": "code",
   "source": [
    "# YT-DLP options\n",
    "def get_opts(output_path):\n",
    "    return {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': output_path,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'quiet': False,\n",
    "        'noplaylist': True,\n",
    "    }"
   ],
   "id": "2e1341dd6b82d666",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Convert YouTube to MP3"
    ]
   },
   "cell_type": "code",
   "source": [
    "# Creates a clean filename for the mp3 files\n",
    "def clean_filename(s):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"\", s.replace(\" \", \"_\"))"
   ],
   "id": "27b350a3cf2e8bd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Convert YouTube to MP3"
    ]
   },
   "cell_type": "code",
   "source": [
    "# Download Loop, record by record\n",
    "for index, row in df.iterrows():\n",
    "    orig_song = clean_filename(row['Original Song'])\n",
    "    orig_artist = clean_filename(row['Original Artist'])\n",
    "    second_song = clean_filename(row['Second Song'])\n",
    "    second_artist = clean_filename(row['Second Artist'])\n",
    "    orig_url = row['Original Song YouTube Link']\n",
    "    second_url = row['Second Song Youtube Link']\n",
    "\n",
    "    row_id = f\"{index+1:03d}\"\n",
    "\n",
    "    # Build filenames\n",
    "    orig_filename = os.path.join(\n",
    "        mp3_song_dir,\n",
    "        f\"{row_id}_original_{orig_song}_by_{orig_artist}.%(ext)s\"\n",
    "    )\n",
    "    second_filename = os.path.join(\n",
    "        mp3_song_dir,\n",
    "        f\"{row_id}_second_{second_song}_by_{second_artist}.%(ext)s\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(get_opts(orig_filename)) as ydl:\n",
    "            print(f\"Downloading original: {orig_song} by {orig_artist}\")\n",
    "            ydl.download([orig_url])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download original song at {orig_url}: {e}\")\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(get_opts(second_filename)) as ydl:\n",
    "            print(f\"Downloading second: {second_song} by {second_artist}\")\n",
    "            ydl.download([second_url])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download second song at {second_url}: {e}\")"
   ],
   "id": "76e323f8fd580e3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Convert YouTube to MP3"
    ]
   },
   "cell_type": "code",
   "source": [
    "# Check how many files were downloaded (should be 176)\n",
    "mp3_files = [f for f in os.listdir(mp3_song_dir) if f.lower().endswith(\".mp3\")]\n",
    "print(f\"Total MP3 files downloaded: {len(mp3_files)}\")"
   ],
   "id": "af5fbd2f7f7a798c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h4><b>1.2 Create Data Structure for known copyrighted song pairings</b></h4>",
   "id": "b560301a5ad5b7a2"
  },
  {
   "metadata": {
    "tags": [
     "Preprocess known copyright pairs"
    ]
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import pickle"
   ],
   "id": "f96d080db2cb9f30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Preprocess known copyright pairs"
    ]
   },
   "cell_type": "code",
   "source": [
    "# Librosa Configuration\n",
    "AUDIO_DIR = mp3_song_dir\n",
    "SR = 16000\n",
    "DURATION = 10\n",
    "TARGET_LEN = DURATION * SR"
   ],
   "id": "c78584cd90cef836",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Preprocess known copyright pairs"
    ]
   },
   "cell_type": "code",
   "source": [
    "def preprocess_audio(audio_path):\n",
    "    \"\"\"Preprocesses .mp3 audio files with specified Librosa Configuration above. Splits each song into chunks of 10 seconds.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        audio_path: str\n",
    "            Path to audio file\n",
    "    RETURNS\n",
    "    -------\n",
    "        list:\n",
    "            A list of numpy arrays, where each array is a 10-second audio chunk of size TARGET_LEN of a song.\n",
    "    \"\"\"\n",
    "\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Trim silent parts (set to top off lower than 20DB)\n",
    "    audio, _ = librosa.effects.trim(audio, top_db=20)\n",
    "\n",
    "    # Resample to 16kHz for Wave2Vec2\n",
    "    if sr != SR:\n",
    "        audio = librosa.resample(audio, orig_sr=sr, target_sr=SR)\n",
    "\n",
    "    # Split song into 10-second chunks of 16kHz\n",
    "    segments = []\n",
    "    for i in range(0, len(audio), TARGET_LEN):\n",
    "        segment = audio[i: (i + TARGET_LEN)]\n",
    "        # If the segment is shorter than TARGET_LEN (i.e. last part of song), pad with zeros for uniformity\n",
    "        if len(segment) < TARGET_LEN:\n",
    "            segment = np.pad(segment, (0, TARGET_LEN - len(segment)), mode='constant')\n",
    "\n",
    "        segments.append(segment)\n",
    "\n",
    "    return segments"
   ],
   "id": "b217ff92343e4b5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Preprocess known copyright pairs"
    ]
   },
   "cell_type": "code",
   "source": [
    "def get_pair_id(audio_filename):\n",
    "    \"\"\"Retrieves pairs of known copyrighted cases from the songs_mp3 directory.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    audio_filename: str\n",
    "        Path to audio file\n",
    "\n",
    "    RETURNS\n",
    "    -------\n",
    "        str:\n",
    "            The pair ID (i.e. \"001\")\n",
    "    \"\"\"\n",
    "    match = re.match(r\"(\\d{3})_\", audio_filename)\n",
    "    return match.group(1) if match else None"
   ],
   "id": "b493a3ce18c39d54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Preprocess known copyright pairs"
    ]
   },
   "cell_type": "code",
   "source": [
    "# Group song mp3 files by pair ID\n",
    "pairs = {}\n",
    "for fname in os.listdir(mp3_song_dir):\n",
    "    if fname.endswith(\".mp3\"):\n",
    "        pair_id = get_pair_id(fname)\n",
    "        if pair_id:\n",
    "            pairs.setdefault(pair_id, []).append(fname)"
   ],
   "id": "601a3aa41f006b06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Preprocess known copyright pairs"
    ]
   },
   "cell_type": "code",
   "source": [
    "# Build dataset from the pairs dictionary intialized in the cell above, preprocess them, and save to pickle file\n",
    "dataset = []\n",
    "preprocessed_output_dir = \"preprocessed_pairs\"\n",
    "os.makedirs(preprocessed_output_dir, exist_ok=True)\n",
    "\n",
    "for pair_id, files in pairs.items():\n",
    "    if len(files) < 2:\n",
    "        print(f\"Skipping {pair_id} expected 2 files but got {len(files)}\")\n",
    "        continue\n",
    "\n",
    "    files = sorted(files) # Original songs [0], copies [1]\n",
    "    og_song = os.path.join(mp3_song_dir, files[0])\n",
    "    copy_song = os.path.join(mp3_song_dir, files[1])\n",
    "\n",
    "    print(f\"Processing pair {pair_id}...\")\n",
    "    segments1 = preprocess_audio(og_song)\n",
    "    print(f\"Preprocessed original song segments: {len(segments1)}\")\n",
    "    segments2 = preprocess_audio(copy_song)\n",
    "    print(f\"Preprocessed copied song segments: {len(segments2)}\")\n",
    "\n",
    "    label = True # True since we are preprocessing all pairs of known copyright infringement cases\n",
    "\n",
    "    pair_data = {\n",
    "        \"pair_id\": pair_id,\n",
    "        \"original_song_segments\": segments1,\n",
    "        \"copied_song_segments\": segments2,\n",
    "        \"label\": label,\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(preprocessed_output_dir, f\"{pair_id}.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(pair_data, f)\n",
    "    print(f\"Saved pair {pair_id} to pickle.\")\n",
    "\n",
    "    dataset.append(pair_data)"
   ],
   "id": "bb96d8da14c79962",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Load preprocessed song pairs"
    ]
   },
   "cell_type": "code",
   "source": [
    "def load_dataset_from_pickles(pickle_dir):\n",
    "    \"\"\"\n",
    "    Handy function to load all preprocessed song pair .pkl files from preprocessed_pairs directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pickle_dir : str\n",
    "        Directory where the pickle files are stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of dictionaries, each containing:\n",
    "            - 'pair_id': str\n",
    "            - 'song1': list of numpy arrays (segments)\n",
    "            - 'song2': list of numpy arrays (segments)\n",
    "            - 'label': bool\n",
    "    \"\"\"\n",
    "    loaded_dataset = []\n",
    "    for pkl_fname in os.listdir(pickle_dir):\n",
    "        if pkl_fname.endswith(\".pkl\"):\n",
    "            path = os.path.join(pickle_dir, pkl_fname)\n",
    "            with open(path, \"rb\") as f:\n",
    "                load_pair_data = pickle.load(f)\n",
    "                loaded_dataset.append(load_pair_data)\n",
    "\n",
    "    return loaded_dataset"
   ],
   "id": "1f067f7f38c093d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h4><b>1.3 Transform preprocessed raw waveforms into feature vector representations with Librosa</b></h4>",
   "id": "8ef80a952fa498dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import librosa.feature as librosa_feature\n",
    "from tqdm import tqdm"
   ],
   "id": "2a97d0a93c2ccbee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_features(audio_segment, sr=16000):\n",
    "    \"\"\"\n",
    "    Extracts a set of audio features for music similarity detection using librosa such as:\n",
    "        - Spectral Features (Timbre, the unique quality of a song's sound)\n",
    "        - Rhythmic Features\n",
    "        - Harmonic and Melodic Features\n",
    "        - Structural Features\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    audio_segment : numpy.ndarray\n",
    "        Raw audio waveform (preprocessed above)\n",
    "    sr : int\n",
    "        Sample rate of the audio waveform\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary that holds the aforementioned audio features\n",
    "    \"\"\"\n",
    "\n",
    "    features = {}\n",
    "    # SPECTRAL FEATURES\n",
    "\n",
    "    # MFCC - captures timbre characteristics (timbre is the unique quality of a song's sound)\n",
    "    mfccs = librosa_feature.mfcc(y=audio_segment, sr=sr, n_mfcc=20)\n",
    "    features['mfcc_mean'] = np.mean(mfccs, axis=1)\n",
    "    features['mfcc_std'] = np.std(mfccs, axis=1)\n",
    "\n",
    "    # Spectral contrast: captures timbral contrast between peaks and valleys\n",
    "    contrast = librosa_feature.spectral_contrast(y=audio_segment, sr=sr)\n",
    "    features['spectral_contrast_mean'] = np.mean(contrast, axis=1)\n",
    "\n",
    "    # Spectral centroid: brightness of sound\n",
    "    centroid = librosa_feature.spectral_centroid(y=audio_segment, sr=sr)[0]\n",
    "    features['spectral_centroid_mean'] = np.mean(centroid)\n",
    "    features['spectral_centroid_std'] = np.std(centroid)\n",
    "\n",
    "    # Spectral rolloff: frequency below which most energy is contained\n",
    "    rolloff = librosa_feature.spectral_rolloff(y=audio_segment, sr=sr)[0]\n",
    "    features['spectral_rolloff_mean'] = np.mean(rolloff)\n",
    "\n",
    "    # Width of spectrum\n",
    "    bandwidth = librosa_feature.spectral_bandwidth(y=audio_segment, sr=sr)[0]\n",
    "    features['spectral_bandwidth_mean'] = np.mean(bandwidth)\n",
    "\n",
    "    # 2. RHYTHM FEATURES\n",
    "\n",
    "    # Tempo and beat sterngth\n",
    "    onset_env = librosa.onset.onset_strength(y=audio_segment, sr=sr)\n",
    "    tempo, beat_frames = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
    "    features['tempo'] = tempo\n",
    "\n",
    "    # Beat intervals if beats were detected\n",
    "    if len(beat_frames) > 1:\n",
    "        beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "        beat_intervals = np.diff(beat_times)\n",
    "        features['beat_intervals_mean'] = np.mean(beat_intervals)\n",
    "        features['beat_intervals_std'] = np.std(beat_intervals)\n",
    "    else:\n",
    "        features['beat_intervals_mean'] = 0\n",
    "        features['beat_intervals_std'] = 0\n",
    "\n",
    "    # Onset detection: where new notes begin\n",
    "    onsets = librosa.onset.onset_detect(y=audio_segment, sr=sr)\n",
    "    features['onset_count'] = len(onsets)\n",
    "\n",
    "    # Rhythm patterns using tempogram\n",
    "    tempogram = librosa_feature.tempogram(onset_envelope=onset_env, sr=sr)\n",
    "    features['tempogram_mean'] = np.mean(tempogram, axis=1)\n",
    "\n",
    "    # 3. HARMONIC AND MELODIC FEATURES\n",
    "\n",
    "    # Separate source audio segment into harmonic and percusive parts\n",
    "    harmonic, percussive = librosa.effects.hpss(audio_segment)\n",
    "\n",
    "    # Evaluates melodic similarities with harmonic audio part\n",
    "    chroma_stft = librosa_feature.chroma_stft(y=harmonic, sr=sr)\n",
    "    features['chroma_stft_mean'] = np.mean(chroma_stft, axis=1)\n",
    "    features['chroma_stft_std'] = np.std(chroma_stft, axis=1)\n",
    "\n",
    "    # Extract pitch related features with harmonic audio part (gets the tonal content)\n",
    "    chroma_cq = librosa_feature.chroma_cqt(y=harmonic, sr=sr)\n",
    "    features['chroma_cq_mean'] = np.mean(chroma_cq, axis=1)\n",
    "    features['chroma_cq_std'] = np.std(chroma_cq, axis=1)\n",
    "\n",
    "    # Tonnetz to measure harmonic relations (like how close 2 chords are on the circle of fifth)\n",
    "    tonnetz = librosa_feature.tonnetz(y=harmonic, sr=sr)\n",
    "    features['tonnetz_mean'] = np.mean(tonnetz, axis=1)\n",
    "    features['tonnetz_std'] = np.std(tonnetz, axis=1)\n",
    "\n",
    "    # 4. STRUCTURAL FEATURES\n",
    "\n",
    "    # Mel spectrogram (log scale)\n",
    "    # Represents the spectral energy across frequency bands, trying to get the overall feel of a song\n",
    "    mel_spec = librosa_feature.melspectrogram(y=audio_segment, sr=sr, n_mels=128)\n",
    "    log_mel_spec = librosa.power_to_db(mel_spec)\n",
    "    features['mel_spec_mean'] = np.mean(log_mel_spec, axis=1)\n",
    "    features['mel_spec_std'] = np.std(log_mel_spec, axis=1)\n",
    "\n",
    "    # Zero-crossing rate (identifies signal crossing the 0 amplitude line)\n",
    "    # High ZCR: noisy, cymbals, Low ZCR: smooth, tonal sounds like vocals or flute for ex.\n",
    "    zcr = librosa_feature.zero_crossing_rate(audio_segment)[0]\n",
    "    features['zcr_mean'] = np.mean(zcr)\n",
    "    features['zcr_std'] = np.std(zcr)\n",
    "\n",
    "    # RMS energy (perceived loudness over time, measures energy dynamics)\n",
    "    rms = librosa_feature.rms(y=audio_segment)[0]\n",
    "    features['rms_mean'] = np.mean(rms)\n",
    "    features['rms_std'] = np.std(rms)\n",
    "\n",
    "    return features"
   ],
   "id": "debb61537a057143",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_features_from_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Process all song pairs and extract features.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset : list\n",
    "        List of dictionaries containing pair_id, original_song_segments, copied_song_segments, and label\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of dictionaries with pair_id, original_features, copied_features, and label\n",
    "    \"\"\"\n",
    "    processed_dataset = []\n",
    "    os.makedirs(\"processed_features\", exist_ok=True)\n",
    "\n",
    "    for pair_data in tqdm(dataset, desc=\"Extracting features from song pairs\"):\n",
    "        pair_id = pair_data['pair_id']\n",
    "        original_segments = pair_data['original_song_segments']\n",
    "        copied_segments = pair_data['copied_song_segments']\n",
    "        label = pair_data['label']\n",
    "\n",
    "        # Extract features for each segment of the original song\n",
    "        original_features = []\n",
    "        for i, segment in enumerate(tqdm(original_segments, desc=f\"Processing original song {pair_id}\", leave=False)):\n",
    "            try:\n",
    "                features = extract_features(segment)\n",
    "                original_features.append(features)\n",
    "\n",
    "                # Save intermediate results every 5 segments\n",
    "                if (i + 1) % 5 == 0:\n",
    "                    with open(f\"processed_features/pair_{pair_id}_original_temp.pkl\", \"wb\") as f:\n",
    "                        pickle.dump(original_features, f)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing segment {i} in original song {pair_id}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Extract features for each segment of the copied song\n",
    "        copied_features = []\n",
    "        for i, segment in enumerate(tqdm(copied_segments, desc=f\"Processing copied song {pair_id}\", leave=False)):\n",
    "            try:\n",
    "                features = extract_features(segment)\n",
    "                copied_features.append(features)\n",
    "\n",
    "                # Save intermediate results every 5 segments\n",
    "                if (i + 1) % 5 == 0:\n",
    "                    with open(f\"processed_features/pair_{pair_id}_copied_temp.pkl\", \"wb\") as f:\n",
    "                        pickle.dump(copied_features, f)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing segment {i} in copied song {pair_id}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Only add to processed dataset if both songs have features extracted\n",
    "        if original_features and copied_features:\n",
    "            processed_pair = {\n",
    "                'pair_id': pair_id,\n",
    "                'original_features': original_features,\n",
    "                'copied_features': copied_features,\n",
    "                'label': label\n",
    "            }\n",
    "            processed_dataset.append(processed_pair)\n",
    "\n",
    "            # Save each processed pair individually\n",
    "            with open(f\"processed_features/pair_{pair_id}_features.pkl\", \"wb\") as f:\n",
    "                pickle.dump(processed_pair, f)\n",
    "\n",
    "    return processed_dataset"
   ],
   "id": "acd21b97be7320c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_data_for_cnn(processed_dataset):\n",
    "    \"\"\"\n",
    "    Convert processed features to vectors suitable for 1D CNN input.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    processed_dataset : list\n",
    "        List of dictionaries with pair_id, original_features, copied_features, and label\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (X_pairs, y) where X_pairs contains paired feature vectors and y contains labels\n",
    "    \"\"\"\n",
    "    X_pairs = []\n",
    "    y = []\n",
    "\n",
    "    for pair_data in processed_dataset:\n",
    "        original_features = pair_data['original_features']\n",
    "        copied_features = pair_data['copied_features']\n",
    "        label = pair_data['label']\n",
    "\n",
    "        # For each pair of segments (one from original, one from copied) create a feature vector pair\n",
    "        for orig_feat in original_features:\n",
    "            for copy_feat in copied_features:\n",
    "                # Convert dictionary features to vector\n",
    "                orig_vector = []\n",
    "                copy_vector = []\n",
    "\n",
    "                # Add all numeric features to vectors\n",
    "                for key, value in orig_feat.items():\n",
    "                    if isinstance(value, np.ndarray):\n",
    "                        orig_vector.extend(value.flatten())\n",
    "                    elif isinstance(value, (int, float)):\n",
    "                        orig_vector.append(value)\n",
    "\n",
    "                for key, value in copy_feat.items():\n",
    "                    if isinstance(value, np.ndarray):\n",
    "                        copy_vector.extend(value.flatten())\n",
    "                    elif isinstance(value, (int, float)):\n",
    "                        copy_vector.append(value)\n",
    "\n",
    "                # Ensure vectors are of equal length by padding if need be\n",
    "                max_len = max(len(orig_vector), len(copy_vector))\n",
    "                orig_vector = np.pad(orig_vector, (0, max_len - len(orig_vector)), 'constant')\n",
    "                copy_vector = np.pad(copy_vector, (0, max_len - len(copy_vector)), 'constant')\n",
    "\n",
    "                # Create pair representation\n",
    "                X_pairs.append([np.array(orig_vector), np.array(copy_vector)])\n",
    "                y.append(label)\n",
    "\n",
    "    return np.array(X_pairs), np.array(y)"
   ],
   "id": "4c1c4821821b90b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load Dataset\n",
    "preprocessed_dataset = load_dataset_from_pickles(preprocessed_output_dir)\n",
    "print(f\"Loaded {len(dataset)} song pairs\")"
   ],
   "id": "a289662b4840b5fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Start Extracting Features\n",
    "os.makedirs(\"features\", exist_ok=True)\n",
    "feat_processed_dataset = extract_features_from_dataset(dataset)\n",
    "with open(\"features/all_processed_features.pkl\", \"wb\") as f:\n",
    "        pickle.dump(feat_processed_dataset, f)"
   ],
   "id": "26e17e2c9471457e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare data for 1D CNN\n",
    "os.makedirs(\"prepared_data_cnn\", exist_ok=True)\n",
    "X_pairs, y = prepare_data_for_cnn(feat_processed_dataset)\n",
    "with open(\"prepared_data_cnn/cnn_ready_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_pairs, y), f)"
   ],
   "id": "acd9744fab0d1a52",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
